{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Churn Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Education</th>\n",
       "      <th>Calls</th>\n",
       "      <th>Visits</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>Lower</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>Lower</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "      <td>Lower</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>Lower</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>Lower</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age Income  FamilySize  Education  Calls  Visits Churn\n",
       "0    Male   34  Lower           4         16     14       5   Yes\n",
       "1    Male   20  Lower           5         14     49       1    No\n",
       "2  Female   30  Lower           4         20     19       4   Yes\n",
       "3  Female   46  Lower           4         14     15       4   Yes\n",
       "4  Female   23  Lower           4         16     18       0    No"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries and my knn class.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import preprocessing\n",
    "from error_metrics import *\n",
    "from knn import * \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('churn_data.csv')\n",
    "validation = pd.read_csv('churn_validation.csv')\n",
    "del data['CustID']\n",
    "del validation['CustID']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the response variable, and what are the predictor variables?\n",
    "The response variable is 'Churn'. The predictor varaibles are 'Gender', 'Age', 'Income', 'FamilySize', 'Education', 'Calls', and 'Visits'.\n",
    "### What data transforms are necessary to perform on this data and why?\n",
    "The column 'CustID' can be deleted because it does not make sense as a predictor variable in this case. Also, all of the predictor columns must be numerical to be able to perform a KNN algorithm so you have to one-hot encode the categorical columns. I scaled the x data so all of the columns would be on the same scale. Also I encoded the y data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select x and y data.\n",
    "features = list(data)\n",
    "features.remove('Churn')\n",
    "data_x = data[features]\n",
    "data_y = data['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class lables to numbers using label encoding.\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_y = le.fit_transform(data_y)\n",
    "\n",
    "# One-Hot Encode features (data_x).\n",
    "def cat_features(dataframe):\n",
    "    td = pd.DataFrame({'a':[1,2,3], 'b':[1.0, 2.0, 3.0]})\n",
    "    return filter(lambda x: not(dataframe[x].dtype in [td['a'].dtype, td['b'].dtype]), list(dataframe))\n",
    "\n",
    "data_x = pd.get_dummies(data_x, columns=list(cat_features(data_x)))\n",
    "\n",
    "# Split into training and test sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Scale data.\n",
    "min_max_scaler = preprocessing.MinMaxScaler() # Default scaled range is [0, 1]\n",
    "\n",
    "# Get the preprocessed training and test data\n",
    "train_x_pp = min_max_scaler.fit_transform(x_train)\n",
    "test_x_pp = min_max_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Different Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. KNN (***class created by me!***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "knn = KNN(5, euclidean)\n",
    "knn.fit(train_x_pp, y_train)\n",
    "y_hat = knn.predict(test_x_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Actual, Predicted): \n",
      "[('Yes', 'No'), ('Yes', 'Yes'), ('Yes', 'Yes'), ('No', 'No'), ('Yes', 'Yes'), ('No', 'Yes'), ('Yes', 'Yes'), ('Yes', 'Yes'), ('Yes', 'Yes'), ('No', 'No'), ('No', 'Yes'), ('Yes', 'No'), ('No', 'Yes'), ('Yes', 'Yes'), ('No', 'Yes'), ('Yes', 'Yes'), ('Yes', 'Yes'), ('No', 'No'), ('Yes', 'Yes'), ('No', 'No'), ('Yes', 'No'), ('Yes', 'Yes'), ('No', 'Yes'), ('No', 'No'), ('Yes', 'Yes'), ('Yes', 'Yes'), ('No', 'No'), ('Yes', 'Yes'), ('No', 'No'), ('Yes', 'No'), ('Yes', 'Yes'), ('Yes', 'Yes'), ('No', 'No'), ('No', 'No'), ('Yes', 'Yes'), ('Yes', 'Yes'), ('No', 'Yes'), ('No', 'No'), ('Yes', 'Yes')]\n"
     ]
    }
   ],
   "source": [
    "# Compare labels.\n",
    "y_test_labs = le.inverse_transform(y_test)\n",
    "y_hat_labs = le.inverse_transform(y_hat)\n",
    "print('(Actual, Predicted): \\n'+str(list(zip(y_test_labs, y_hat_labs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- EVALUATING MODEL: k = 5-----------\n",
      "Accuracy: 0.7435897435897436\n",
      "Precision: 0.76\n",
      "Recall: 0.8260869565217391\n",
      "F1: 0.7916666666666667\n",
      "ROC AUC: 0.7255434782608695\n",
      "Confusion Matrix: \n",
      "[[10  6]\n",
      " [ 4 19]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate results at k.\n",
    "print('--------- EVALUATING MODEL: k = '+str(knn.k)+ '-----------')\n",
    "print('Accuracy: '+str(accuracy_score(y_test, y_hat)))\n",
    "print('Precision: '+str(precision_score(y_test, y_hat)))\n",
    "print('Recall: '+str(recall_score(y_test, y_hat)))\n",
    "print('F1: '+str(f1_score(y_test, y_hat)))\n",
    "print('ROC AUC: '+str(roc_auc_score(y_test, y_hat)))\n",
    "print('Confusion Matrix: \\n'+str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717948717948718\n",
      "Avg. F1 (Micro): 0.717948717948718\n",
      "Avg. F1 (Macro): 0.6980999296270232\n",
      "Avg. F1 (Weighted): 0.7119940814522095\n",
      "Confusion Matrix: \n",
      "[[ 9  7]\n",
      " [ 4 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.69      0.62        13\n",
      "           1       0.83      0.73      0.78        26\n",
      "\n",
      "   micro avg       0.72      0.72      0.72        39\n",
      "   macro avg       0.69      0.71      0.70        39\n",
      "weighted avg       0.74      0.72      0.72        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build and evaluate the model.\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "nb_mod = naive_bayes.GaussianNB()\n",
    "nb_mod.fit(train_x_pp, y_train)\n",
    "y_hat = nb_mod.predict(test_x_pp)\n",
    "print_multiclass_classif_error_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7948717948717948\n",
      "Avg. F1 (Micro): 0.7948717948717948\n",
      "Avg. F1 (Macro): 0.7771428571428571\n",
      "Avg. F1 (Weighted): 0.7884249084249085\n",
      "Confusion Matrix: \n",
      "[[10  6]\n",
      " [ 2 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71        12\n",
      "           1       0.91      0.78      0.84        27\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        39\n",
      "   macro avg       0.77      0.81      0.78        39\n",
      "weighted avg       0.82      0.79      0.80        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Information Entropy approach.\n",
    "dtree_ent = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "dtree_ent.fit(train_x_pp, y_train)\n",
    "y_hat_ent = dtree_ent.predict(test_x_pp)\n",
    "print_multiclass_classif_error_report(y_test, y_hat_ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------EVALUATING MODEL: n_estimators = 50, max_depth = 6--------\n",
      "Accuracy: 0.8205128205128205\n",
      "Avg. F1 (Micro): 0.8205128205128205\n",
      "Avg. F1 (Macro): 0.8078817733990148\n",
      "Avg. F1 (Weighted): 0.8167235063786789\n",
      "Confusion Matrix: \n",
      "[[11  5]\n",
      " [ 2 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76        13\n",
      "           1       0.91      0.81      0.86        26\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        39\n",
      "   macro avg       0.80      0.83      0.81        39\n",
      "weighted avg       0.84      0.82      0.82        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a sequence of Random Forest models for different n_est and depth values.\n",
    "from sklearn import ensemble\n",
    "\n",
    "n_ests = [50]\n",
    "depths = [6]\n",
    "for n in n_ests:\n",
    "    for dp in depths:\n",
    "        rf = ensemble.RandomForestClassifier(n_estimators=n, max_depth=dp)\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_hat = rf.predict(x_test)\n",
    "        print('--------EVALUATING MODEL: n_estimators = '+str(n)+', max_depth = '+str(dp)+'--------')\n",
    "        print_multiclass_classif_error_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- EVALUATING MODEL: C = 1.5 ------------\n",
      "Accuracy: 0.6153846153846154\n",
      "Avg. F1 (Micro): 0.6153846153846154\n",
      "Avg. F1 (Macro): 0.5883180858550316\n",
      "Avg. F1 (Weighted): 0.6072646565257401\n",
      "Confusion Matrix: \n",
      "[[ 7  9]\n",
      " [ 6 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.54      0.48        13\n",
      "           1       0.74      0.65      0.69        26\n",
      "\n",
      "   micro avg       0.62      0.62      0.62        39\n",
      "   macro avg       0.59      0.60      0.59        39\n",
      "weighted avg       0.64      0.62      0.62        39\n",
      "\n",
      "--------- EVALUATING MODEL: C = 2.0 ------------\n",
      "Accuracy: 0.6410256410256411\n",
      "Avg. F1 (Micro): 0.6410256410256411\n",
      "Avg. F1 (Macro): 0.61\n",
      "Avg. F1 (Weighted): 0.6297435897435897\n",
      "Confusion Matrix: \n",
      "[[ 7  9]\n",
      " [ 5 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.58      0.50        12\n",
      "           1       0.78      0.67      0.72        27\n",
      "\n",
      "   micro avg       0.64      0.64      0.64        39\n",
      "   macro avg       0.61      0.62      0.61        39\n",
      "weighted avg       0.68      0.64      0.65        39\n",
      "\n",
      "--------- EVALUATING MODEL: C = 2.5 ------------\n",
      "Accuracy: 0.6666666666666666\n",
      "Avg. F1 (Micro): 0.6666666666666666\n",
      "Avg. F1 (Macro): 0.6318082788671024\n",
      "Avg. F1 (Weighted): 0.6521423384168483\n",
      "Confusion Matrix: \n",
      "[[ 7  9]\n",
      " [ 4 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.64      0.52        11\n",
      "           1       0.83      0.68      0.75        28\n",
      "\n",
      "   micro avg       0.67      0.67      0.67        39\n",
      "   macro avg       0.63      0.66      0.63        39\n",
      "weighted avg       0.72      0.67      0.68        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Make a sequence of SVM classifiers for different values of error term c. **Note: c=1.0 is default.\n",
    "from sklearn import svm\n",
    "\n",
    "cs = [1.5, 2.0, 2.5]\n",
    "for c in cs:\n",
    "    # Create model and fit\n",
    "    mod = svm.SVC(C=c)\n",
    "    mod.fit(train_x_pp, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_hat = mod.predict(test_x_pp)\n",
    "    print('--------- EVALUATING MODEL: C = ' + str(c) + ' ------------')\n",
    "    print_multiclass_classif_error_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Models\n",
    "What modeling approaches did you use and why? Describe your model development process, including the different models tried, feature selection methods, and the different transformation techniques you employed.\n",
    "Which error metrics did you use to assess performance and why? What kind of performance did you obtain on the different models you built?\n",
    "\n",
    "I tried the KNN class that I created, Naive Bayes, Decision Tree, Random Forest, and SVM. I mainly assessed the accuracy score and confusion matrix when I compared the different models. They all seemed to perform pretty well but I chose to develop the Random Forest model further because it had the best results on its own. It had an accuracy score of 0.8205128205128205 with 50 estimators and a max depth of 6. I was very happy with the KNN class that I created because it had an accuracy score of 0.7435897435897436 and a precision score of 0.7142857142857143. I thought that it would be a lot worse because the algorithm I created was not very complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set:\n",
    "Load the dataset “churn_validation.csv” into a new data frame and recode as necessary. Predict the outcomes for each of the customers and compare to the actual. What are the error rates you get based on your selected metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Education</th>\n",
       "      <th>Calls</th>\n",
       "      <th>Visits</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Income_Lower</th>\n",
       "      <th>Income_Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  FamilySize  Education  Calls  Visits  Gender_Female  Gender_Male  \\\n",
       "0   54           4         18     48       3              0            1   \n",
       "1   21           4         19     44       2              0            1   \n",
       "2   22           3         16     22       5              1            0   \n",
       "3   27           3         13     19       2              0            1   \n",
       "4   18           2         14      6       3              0            1   \n",
       "\n",
       "   Income_Lower  Income_Upper  \n",
       "0             0             1  \n",
       "1             1             0  \n",
       "2             1             0  \n",
       "3             0             1  \n",
       "4             1             0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform validation set.\n",
    "\n",
    "# Select x and y data.\n",
    "features = list(validation)\n",
    "features.remove('Churn')\n",
    "val_x = validation[features]\n",
    "val_y = validation['Churn']\n",
    "\n",
    "# Convert class lables to numbers using label encoding.\n",
    "le = preprocessing.LabelEncoder()\n",
    "val_y = le.fit_transform(val_y)\n",
    "\n",
    "# One-Hot Encode features (val_x).\n",
    "val_x = pd.get_dummies(val_x, columns=list(cat_features(val_x)))\n",
    "\n",
    "val_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65625\n",
      "Avg. F1 (Micro): 0.65625\n",
      "Avg. F1 (Macro): 0.6559139784946237\n",
      "Avg. F1 (Weighted): 0.6545698924731183\n",
      "Confusion Matrix: \n",
      "[[11  3]\n",
      " [ 8 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.58      0.67        19\n",
      "           1       0.56      0.77      0.65        13\n",
      "\n",
      "   micro avg       0.66      0.66      0.66        32\n",
      "   macro avg       0.67      0.67      0.66        32\n",
      "weighted avg       0.69      0.66      0.66        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run validation set on Random Forest Model. \n",
    "y_pred = rf.predict(val_x)\n",
    "print_multiclass_classif_error_report(y_pred, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Actual, Predicted): \n",
      "[('Yes', 'Yes'), ('Yes', 'Yes'), ('Yes', 'Yes'), ('Yes', 'Yes'), ('No', 'No'), ('Yes', 'Yes'), ('No', 'No'), ('Yes', 'No'), ('Yes', 'Yes'), ('No', 'No'), ('No', 'No'), ('No', 'Yes'), ('Yes', 'Yes'), ('No', 'No'), ('Yes', 'Yes'), ('No', 'Yes'), ('Yes', 'No'), ('No', 'No'), ('No', 'Yes'), ('No', 'No'), ('No', 'No'), ('No', 'No'), ('No', 'Yes'), ('No', 'Yes'), ('Yes', 'Yes'), ('No', 'Yes'), ('No', 'Yes'), ('Yes', 'Yes'), ('No', 'No'), ('No', 'No'), ('Yes', 'No'), ('No', 'Yes')]\n"
     ]
    }
   ],
   "source": [
    "# Compare labels.\n",
    "y_labels = le.inverse_transform(val_y)\n",
    "y_pred_labs = le.inverse_transform(y_pred)\n",
    "print('(Actual, Predicted): \\n'+str(list(zip(y_labels, y_pred_labs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This model has an accuracy score of 0.65625 on the validation set. This isn't bad but it is not the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
